{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "lone_pine = pd.read_csv(r'C:\\Users\\wells\\OneDrive\\Desktop\\lone_pine.csv')\n",
    "crsp_data = pd.read_csv('StockPriceMonthly.csv', encoding='utf8', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine['Ticker'] = lone_pine['Ticker'].astype('str')\n",
    "def ab(aa):\n",
    "    if '.' in aa:\n",
    "        return aa.split('.')[0]\n",
    "    if '/' in aa:\n",
    "        return aa.split('/')[0]\n",
    "    else:\n",
    "        return aa\n",
    "lone_pine['Ticker'] = lone_pine['Ticker'].apply(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(aa):\n",
    "    aa = aa.split('/')\n",
    "    year = aa[2]\n",
    "    month = aa[0]\n",
    "    day = aa[1]\n",
    "    return year+month\n",
    "lone_pine['Date'] = lone_pine['Date'].apply(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def abcd(aa):\n",
    "    return str(aa)[0:6]\n",
    "crsp_data['date'] = crsp_data['date'].apply(abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bae4535b07425884fc152fcd78c43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3467), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "add_df = pd.DataFrame(columns=lone_pine.columns)\n",
    "for index in tqdm_notebook(range(len(lone_pine))):\n",
    "    each_data = lone_pine.loc[index]\n",
    "    date = int(each_data['Date'])\n",
    "    if date % 4 == 0:\n",
    "        date = date - 12 + 100\n",
    "    each_data['Date'] = str(date+1)\n",
    "    each_data['Change'] = 0\n",
    "    each_data['Change.1'] = 0\n",
    "    add_df.loc[-1] = list(each_data)\n",
    "    add_df = add_df.reset_index(drop=True)\n",
    "    date = int(each_data['Date'])\n",
    "    each_data['Date'] = str(date+1)\n",
    "    each_data['Change'] = 0\n",
    "    each_data['Change.1'] = 0\n",
    "    add_df.loc[-1] = list(each_data)\n",
    "    add_df = add_df.reset_index(drop=True)\n",
    "lone_pine_a = pd.concat([lone_pine, add_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def class_(df_col):\n",
    "    if df_col == 'CL A':\n",
    "        return 'A'\n",
    "    elif df_col == 'CL B':\n",
    "        return 'B'\n",
    "    elif df_col == 'CL C':\n",
    "        return 'C'\n",
    "    elif df_col == 'CL D':\n",
    "        return 'D'\n",
    "    else:\n",
    "        return np.nan\n",
    "lone_pine_a['Class'] = lone_pine_a['Class'].apply(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def division(df):\n",
    "    if df['Shares'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return df['Value'] / df['Shares']\n",
    "lone_pine_a['price'] = lone_pine_a.apply(division, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crsp_data.columns = ['PERMNO', 'Date', 'Ticker', 'COMNAM', 'Class', 'DIVAMT', 'PRC', 'VOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def class_1(df_col):\n",
    "#     if df_col == 'A':\n",
    "#         return 'A'\n",
    "#     elif df_col == 'B':\n",
    "#         return 'B'\n",
    "#     elif df_col == 'C':\n",
    "#         return 'C'\n",
    "#     elif df_col == 'D':\n",
    "#         return 'D'\n",
    "#     else:\n",
    "#         return 0\n",
    "# crsp_data['Class'] = crsp_data['Class'].apply(class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_abs(df_col):\n",
    "    return abs(df_col)\n",
    "crsp_data_c = crsp_data[['Date', 'Ticker', 'PRC', 'Class']]\n",
    "crsp_data_c = crsp_data_c[crsp_data_c['PRC'].notnull()].drop_duplicates(keep='first')\n",
    "crsp_data_c['PRC'] = crsp_data_c['PRC'].apply(to_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all = lone_pine_a.merge(crsp_data_c, on=['Date', 'Ticker'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all.drop(['% Port', '% OS', 'Hist'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(set(list(lone_pine_all['Name']))):\n",
    "    if len(lone_pine_a[lone_pine_a['Name']==name].reset_index(drop=True)) != len(lone_pine_all[lone_pine_all['Name']==name].reset_index(drop=True)):\n",
    "        drop_df = lone_pine_all[lone_pine_all['Name']==name].loc[lone_pine_all['Class_x']!=lone_pine_all['Class_y']]\n",
    "        lone_pine_all.drop(list(drop_df.index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c36193953254b9da8831833087ba9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=433), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "lone_pine_all = lone_pine_all.sort_values(by='Date').reset_index(drop=True)\n",
    "df_list = []\n",
    "for each in tqdm_notebook(lone_pine_all.groupby(by='Name')):\n",
    "    name, df = each\n",
    "    df.loc[:, 'last_price'] = df['price'].shift()\n",
    "    df.loc[:, 'last_PRC'] = df['PRC'].shift()\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = lone_pine_all[lone_pine_all['PRC'].isnull()][['Name', 'Ticker', 'PRC', 'Date']].drop_duplicates(keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaed5b3fd244fd8a92f80f657a18526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=511), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = lone_pine_all\n",
    "new_error = []\n",
    "for index in tqdm_notebook(error.index):\n",
    "    each = error.loc[index]\n",
    "    df = crsp_data[crsp_data['Ticker']==each['Ticker']]\n",
    "    try:\n",
    "        if int(each['Date']) > int(list(df['Date'])[-1]):\n",
    "            test = test.drop(index)\n",
    "    except:\n",
    "        new_error.append(list(each))\n",
    "lone_pine_all = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(new_error).to_csv('error.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d330326a9444e3b508e02892d3fd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10174), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lone_pine_all_t = lone_pine_all\n",
    "for index in tqdm_notebook(lone_pine_all.index):\n",
    "    each_data = lone_pine_all.loc[index]\n",
    "    if each_data['Shares'] == 0 and each_data['Change'] == 0 and each_data['Value'] == 0 and each_data['Change.1'] == 0:\n",
    "        lone_pine_all_t.drop(index, inplace=True)\n",
    "lone_pine_all = lone_pine_all_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prc_price(df):\n",
    "    if np.isnan(df['PRC']):\n",
    "        return df['price']\n",
    "    else:\n",
    "        return df['PRC']\n",
    "lone_pine_all['PRC'] = lone_pine_all.apply(prc_price, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prc_price(df):\n",
    "    if np.isnan(df['last_PRC']):\n",
    "        return df['last_price']\n",
    "    else:\n",
    "        return df['last_PRC']\n",
    "lone_pine_all['last_PRC'] = lone_pine_all.apply(prc_price, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all.drop(['Class_x', 'price', 'last_price', 'price'], axis=1, inplace=True)\n",
    "lone_pine_all.columns = ['Name', 'Ticker', 'Shares', 'Shares_Change', 'Value', 'Value_Change', 'Date', 'Price',\n",
    "                         'Class', 'Last_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "new_share = lone_pine_all[lone_pine_all['Shares']==lone_pine_all['Shares_Change']]\n",
    "new_share['New_Value'] = new_share['Shares'] * new_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_share.to_csv('new_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sell_share = lone_pine_all[lone_pine_all['Shares']==0]\n",
    "sell_share['New_Value'] = sell_share['Shares_Change'] * sell_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_share.to_csv('sell_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_share = lone_pine_all[lone_pine_all['Shares_Change']>0].loc[lone_pine_all['Shares']!=lone_pine_all['Shares_Change']]\n",
    "more_share['New_Value'] = more_share['Shares'] * more_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_share.to_csv('more_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_share = lone_pine_all[lone_pine_all['Shares_Change']<0].loc[lone_pine_all['Shares']!=0]\n",
    "less_share['New_Value'] = (less_share['Shares'] + abs(less_share['Shares_Change'])) * less_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_share.to_csv('less_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "same_share = lone_pine_all[lone_pine_all['Shares_Change']==0]\n",
    "same_share['New_Value'] = same_share['Shares'] * same_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_share.to_csv('same_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_asset = []\n",
    "for date in list(set(lone_pine_all['Date'])):\n",
    "    lone_pine_all_t = lone_pine_all[lone_pine_all['Date']==date]\n",
    "    total_asset.append(sum(lone_pine_all_t['New_Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "revenue = []\n",
    "for date in list(set(lone_pine_all['Date'])):\n",
    "    lone_pine_all_t = lone_pine_all[lone_pine_all['Date']==date]\n",
    "\n",
    "    sell_shares = lone_pine_all_t[lone_pine_all_t['Shares']==0]\n",
    "    more_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']>0].loc[lone_pine_all_t['Shares']!=lone_pine_all_t['Shares_Change']]\n",
    "    less_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']<0].loc[lone_pine_all_t['Shares']!=0]\n",
    "    same_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']==0]\n",
    "\n",
    "    sell_shares['diff'] = abs(sell_shares['Shares_Change']) * (sell_shares['Price'] - sell_shares['Last_Price'])\n",
    "    more_shares['diff'] = (more_shares['Shares'] - more_shares['Shares_Change']) * (more_shares['Price'] - more_shares['Last_Price'])\n",
    "    less_shares['diff'] = (less_shares['Shares'] + abs(less_shares['Shares_Change'])) * (less_shares['Price'] - less_shares['Last_Price'])\n",
    "    same_shares['diff'] = same_shares['Shares'] * (same_shares['Price'] - same_shares['Last_Price'])\n",
    "    \n",
    "    sell_shares = sell_shares[sell_shares['diff'].notnull()]\n",
    "    more_shares = more_shares[more_shares['diff'].notnull()]\n",
    "    less_shares = less_shares[less_shares['diff'].notnull()]\n",
    "    same_shares = same_shares[same_shares['diff'].notnull()]\n",
    "    \n",
    "    revenue.append(sum(sell_shares['diff']) + sum(more_shares['diff']) + sum(less_shares['diff']) + sum(same_shares['diff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = pd.DataFrame({'date':list(set(lone_pine_all['Date'])),\n",
    "                          'asset':total_asset,\n",
    "                          'revenue':revenue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = revenue_df.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df['last_asset'] = revenue_df['asset'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df['return_rate'] = round(revenue_df['revenue'] / revenue_df['last_asset'] * 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fama = pd.read_csv('fama.csv')\n",
    "fama['date'] = fama['date'].astype('str')\n",
    "\n",
    "fama_3 = fama.merge(revenue_df[['date', 'return_rate']], on='date', how='left')\n",
    "\n",
    "fama_3 = fama_3[fama_3['return_rate'].notnull()]\n",
    "\n",
    "fama_3['return_rate'] = fama_3['return_rate'] - fama_3['RF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "fama = pd.read_csv('fama5.csv')\n",
    "fama['date'] = fama['date'].astype('str')\n",
    "\n",
    "fama_5 = fama.merge(revenue_df[['date', 'return_rate']], on='date', how='left')\n",
    "\n",
    "fama_5 = fama_5[fama_5['return_rate'].notnull()]\n",
    "\n",
    "fama_5['return_rate'] = fama_5['return_rate'] - fama_5['RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "alpha = 5\n",
    "while alpha > 0.001:\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = lasso.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = lasso.predict(x_test_std)\n",
    "    score = r2_score(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(lasso.coef_!=0)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    alpha_df.loc[-1] = [alpha] + list(lasso.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.012488949939432725\n",
      "test_score: -13.421032393251707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "      <th>coeff_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.000</td>\n",
       "      <td>-3.324834</td>\n",
       "      <td>17.456317</td>\n",
       "      <td>11.435653</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>-13.421032</td>\n",
       "      <td>444.592189</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.999</td>\n",
       "      <td>-3.326621</td>\n",
       "      <td>17.457768</td>\n",
       "      <td>11.436771</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>-13.421664</td>\n",
       "      <td>444.611653</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.998</td>\n",
       "      <td>-3.328407</td>\n",
       "      <td>17.459218</td>\n",
       "      <td>11.437888</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>-13.422295</td>\n",
       "      <td>444.631123</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.997</td>\n",
       "      <td>-3.330193</td>\n",
       "      <td>17.460669</td>\n",
       "      <td>11.439006</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>-13.422927</td>\n",
       "      <td>444.650599</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.996</td>\n",
       "      <td>-3.331979</td>\n",
       "      <td>17.462120</td>\n",
       "      <td>11.440123</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>-13.423559</td>\n",
       "      <td>444.670081</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.995</td>\n",
       "      <td>-3.333765</td>\n",
       "      <td>17.463571</td>\n",
       "      <td>11.441241</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>-13.424191</td>\n",
       "      <td>444.689570</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha     coef1      coef2      coef3  train_score  test_score           e  \\\n",
       "0  5.000 -3.324834  17.456317  11.435653     0.010968  -13.421032  444.592189   \n",
       "1  4.999 -3.326621  17.457768  11.436771     0.010968  -13.421664  444.611653   \n",
       "2  4.998 -3.328407  17.459218  11.437888     0.010969  -13.422295  444.631123   \n",
       "3  4.997 -3.330193  17.460669  11.439006     0.010970  -13.422927  444.650599   \n",
       "4  4.996 -3.331979  17.462120  11.440123     0.010970  -13.423559  444.670081   \n",
       "5  4.995 -3.333765  17.463571  11.441241     0.010971  -13.424191  444.689570   \n",
       "\n",
       "   coeff_used  \n",
       "0         3.0  \n",
       "1         3.0  \n",
       "2         3.0  \n",
       "3         3.0  \n",
       "4         3.0  \n",
       "5         3.0  "
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))\n",
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "alpha = 5\n",
    "while alpha > 0.001:\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = lasso.predict(x_train_std)\n",
    "    score_train=r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = lasso.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(lasso.coef_!=0)\n",
    "    alpha_df.loc[-1] = [alpha] + list(lasso.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))\n",
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "alpha = 5\n",
    "while alpha >= 0.001:\n",
    "    rr = Ridge(alpha)\n",
    "    rr.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = rr.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = rr.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(rr.coef_!=0)\n",
    "    alpha_df.loc[-1] = [alpha] + list(rr.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.015562905934369708\n",
      "test_score: -89.9436077742032\n"
     ]
    }
   ],
   "source": [
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]\n",
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "alpha = 5\n",
    "while alpha >= 0.001:\n",
    "    rr = Ridge(alpha)\n",
    "    rr.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = rr.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = rr.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(rr.coef_!=0)\n",
    "    alpha_df.loc[-1] = [alpha] + list(rr.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.022269273889409247\n",
      "test_score: -68.72711893122063\n"
     ]
    }
   ],
   "source": [
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]\n",
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.DataFrame(columns=['c', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "c = 100\n",
    "while c > 1:\n",
    "    svr_lin = SVR(kernel='linear', C=c, gamma='auto')\n",
    "    svr_lin.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = svr_lin.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = svr_lin.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(svr_lin.coef_!=0)\n",
    "    c_df.loc[-1] = [c] + list(svr_lin.coef_[0]) + [score_train, score, e, coeff_used]\n",
    "    c_df = c_df.reset_index(drop=True)\n",
    "    c = c - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.022269273889409247\n",
      "test_score: -68.72711893122063\n"
     ]
    }
   ],
   "source": [
    "c_df.sort_values(by='test_score', ascending=False)[0:6]\n",
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "c = 100\n",
    "while c > 1:\n",
    "    svr_lin = SVR(kernel='linear', C=c, gamma='auto')\n",
    "    svr_lin.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = svr_lin.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = svr_lin.fit(x_train_std, y_train['return_rate'].values).predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(svr_lin.coef_!=0)\n",
    "    c_df.loc[-1] = [c] + list(svr_lin.coef_[0]) + [score_train, score, e, coeff_used]\n",
    "    c_df = c_df.reset_index(drop=True)\n",
    "    c = c - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.022269273889409247\n",
      "test_score: -68.72711893122063\n"
     ]
    }
   ],
   "source": [
    "c_df.sort_values(by='test_score', ascending=False)[0:6]\n",
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [-14.87442408  31.13021482  18.7217049 ]\n",
      "score_train: 0.01735656040364142\n",
      "score_prediction: -5.9545065294916135\n",
      "e: 2850.6897801390965\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(alpha)\n",
    "lr.fit(x_train_std, y_train['return_rate'].values)\n",
    "y_predict_train = lr.predict(x_train_std)\n",
    "score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "y_predict = lr.predict(x_test_std)\n",
    "score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "coeff_used = np.sum(lr.coef_!=0)\n",
    "print('coef:', lr.coef_)\n",
    "print('score_train:',score_train)\n",
    "print('score_prediction:',score)\n",
    "print('e:',e)\n",
    "# list(lr.coef_) + [score_train, score, e, coeff_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [ 5.05150275 -1.69255817 -0.18464175  0.05059647 -0.91706958]\n",
      "score_train: 0.1365749511987725\n",
      "score_prediction: -0.02487743179242141\n",
      "e: 213166.8130206327\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(alpha)\n",
    "lr.fit(x_train_std, y_train['return_rate'].values)\n",
    "y_predict_train = lr.predict(x_train_std)\n",
    "score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "y_predict = lr.predict(x_test_std)\n",
    "score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "coeff_used = np.sum(lr.coef_!=0)\n",
    "print('coef:', lr.coef_)\n",
    "print('score_train:',score_train)\n",
    "print('score_prediction:',score)\n",
    "print('e:',e)\n",
    "# list(lr.coef_) + [score, e, coeff_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
